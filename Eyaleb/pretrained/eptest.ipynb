{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a333d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import tensorflow.compat.v1 as tf\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy import linalg\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from tensorflow.keras import backend as B\n",
    "from tensorflow.keras.layers import Input,Dense,Lambda,Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from munkres import Munkres\n",
    "k_cluster = 38\n",
    "batchSize=486\n",
    "\n",
    "x_train=np.load('../../datasets/eyaleb/d_eyalebtrain.npy')\n",
    "x_train=x_train.reshape(len(x_train)*batchSize,784)\n",
    "y=np.load('../../datasets/eyaleb/l_eyalebtrain.npy')\n",
    "y=y.reshape(len(y)*batchSize,)\n",
    "alpha_trans1=np.load('../../datasets/eyaleb/h_eyalebtrain.npy',allow_pickle=True)\n",
    "alpha_trans1=np.asarray(alpha_trans1).astype('float32') \n",
    "\n",
    "x=np.load('../../datasets/eyaleb/d_eyaleb.npy')\n",
    "x=x.reshape(len(x)*batchSize,784)\n",
    "x_test=x[len(x_train):,:]\n",
    "y1=np.load('../../datasets/eyaleb/l_eyaleb.npy')\n",
    "y1=y1.reshape(len(y1)*batchSize,)\n",
    "y_test=y1[len(y):,]\n",
    "y_test=y_test.reshape(len(y_test),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8022fdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cost_matrix(c1, c2):\n",
    "    uc1 = np.unique(c1)\n",
    "    uc2 = np.unique(c2)\n",
    "    l1 = uc1.size\n",
    "    l2 = uc2.size\n",
    "    for a in range (1):\n",
    "        if uc1.shape==uc2.shape:\n",
    "            m = np.ones([l1, l2])\n",
    "            for i in range(l1):\n",
    "                it_i = np.nonzero(c1 == uc1[i])[0]\n",
    "                for j in range(l2):\n",
    "                    it_j = np.nonzero(c2 == uc2[j])[0]\n",
    "                    m_ij = np.intersect1d(it_j, it_i)\n",
    "                    m[i,j] =  -m_ij.size\n",
    "        else:\n",
    "            print('assertion handeled')\n",
    "            return\n",
    "        #break\n",
    "    return m\n",
    "\n",
    "\n",
    "def translate_clustering(clt, mapper):\n",
    "    return np.array([ mapper[i] for i in clt ])\n",
    "\n",
    "def accuracy(cm):\n",
    "    return np.trace(cm, dtype=float) / np.sum(cm)\n",
    "\n",
    "def rectify_label(labels, classes):\n",
    "    num_labels = len(np.unique(classes))\n",
    "    cm = confusion_matrix(classes, labels, labels=range(num_labels)) # gets the confusion matrix\n",
    "    cost_matrix = make_cost_matrix(labels, classes)\n",
    "    if cost_matrix is None:\n",
    "        return (None,None)\n",
    "    else:\n",
    "        m = Munkres()\n",
    "        indexes = m.compute(cost_matrix)\n",
    "        mapper = { old: new for (old, new) in indexes }\n",
    "        new_labels = translate_clustering(labels, mapper)\n",
    "        new_cm = confusion_matrix(classes, new_labels, labels=range(num_labels))\n",
    "        return new_labels,accuracy(new_cm)\n",
    "\n",
    "def arch():\n",
    "    encoding_dim = 484 \n",
    "    input_img = Input(shape=(784,))\n",
    "    encoded_layer_2 = Dense(700, activation='tanh')(input_img)\n",
    "    encoded_layer_3 = Dense(600, activation='tanh')(encoded_layer_2)\n",
    "    encoded_layer_4 = Dense(500, activation='tanh')(encoded_layer_3)\n",
    "    encoded = Dense(encoding_dim, activation='tanh')(encoded_layer_4)\n",
    "    decoded_layer_2 = Dense(500, activation='tanh')(encoded)\n",
    "    decoded_layer_3 = Dense(600, activation='tanh')(decoded_layer_2)\n",
    "    decoded_layer_4 = Dense(700, activation='tanh')(decoded_layer_3)\n",
    "    decoded = Dense(784, activation='tanh')(decoded_layer_4)\n",
    "    encoder=Model(input_img,encoded)\n",
    "    autoencoder=Model(input_img,decoded)\n",
    "    return encoder,encoding_dim,autoencoder\n",
    "  \n",
    "def assign_func(z_test,z_ic):\n",
    "    dst = np.array(np.sum(((z_test-z_ic[0]) **2),axis=1))\n",
    "    for index in range(1, z_ic.shape[0]):\n",
    "        col = np.sum(((z_test- z_ic[index])**2), axis=1)\n",
    "        dst = np.vstack((dst, col))\n",
    "    dst = dst.T         \n",
    "    mean_dst = np.mean(dst, axis=1)\n",
    "    q = np.maximum(0.0, np.tile(mean_dst, (dst.shape[1], 1)).T - dst)\n",
    "    #print(q.shape)\n",
    "    num_centers = q.shape[1]\n",
    "    weight = 1.0 / (q.sum(axis=0) + 1e-9)\n",
    "    weight *= num_centers / weight.sum()\n",
    "    q = (q ** 2.0) * weight\n",
    "    q = (q.T / (q.sum(axis=1) + B.epsilon())).T\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e07d7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on eyaleb test dataset: accuracy is, nmi is, f1 score is, precision is... 1.0 1.0 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "encoder,encoding_dim,autoencoder=arch()\n",
    "encoder.load_weights('../../checkpoints/eyaleb/sdsc_eyalebtrain.ckpt')\n",
    "z_test=encoder.predict(x_test)\n",
    "ic= np.load('../../checkpoints/eyaleb/sdsc_eyalebictrain.npy')\n",
    "assignment = assign_func(z_test, ic)\n",
    "predictedlabels = np.argmax(assignment, axis=1)\n",
    "rectified_label, acc=rectify_label(predictedlabels, y_test)\n",
    "nmi=sklearn.metrics.normalized_mutual_info_score(y_test, rectified_label)\n",
    "f1=sklearn.metrics.f1_score(y_test, rectified_label,average='micro')\n",
    "prec=sklearn.metrics.precision_score(y_test, rectified_label,average='weighted')\n",
    "print('Results on eyaleb test dataset: accuracy is, nmi is, f1 score is, precision is...',acc,nmi,f1,prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dc81da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
