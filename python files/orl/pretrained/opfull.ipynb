{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6c6aac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_train=np.load('../../../datasets/ORL/d_orl.npy')\n",
    "x_train=x_train.reshape(x_train.shape[0]*x_train.shape[1],400)\n",
    "y=np.load('../../../datasets/ORL/l_orl.npy')\n",
    "y=y.reshape(y.shape[0]*y.shape[1],)\n",
    "alpha_trans1=np.load('../../../datasets/ORL/Sb_orl.npy',allow_pickle=True)\n",
    "alpha_trans1=np.asarray(alpha_trans1).astype('float32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44cf56e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow.compat.v1 as tf\n",
    "import os\n",
    "\n",
    "batchSize=400\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.linalg import fractional_matrix_power\n",
    "from scipy import linalg\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from tensorflow.keras import backend as B\n",
    "k_cluster = 40\n",
    "from tensorflow.keras.layers import Input,Dense,Lambda,Layer\n",
    "from tensorflow.keras.models import Model\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from munkres import Munkres\n",
    "import cv2\n",
    "from numpy import save\n",
    "\n",
    "\n",
    "def make_cost_matrix(c1, c2):\n",
    "    uc1 = np.unique(c1)\n",
    "    uc2 = np.unique(c2)\n",
    "    l1 = uc1.size\n",
    "    l2 = uc2.size\n",
    "    for a in range (1):\n",
    "        if uc1.shape==uc2.shape:\n",
    "            m = np.ones([l1, l2])\n",
    "            for i in range(l1):\n",
    "                it_i = np.nonzero(c1 == uc1[i])[0]\n",
    "                for j in range(l2):\n",
    "                    it_j = np.nonzero(c2 == uc2[j])[0]\n",
    "                    m_ij = np.intersect1d(it_j, it_i)\n",
    "                    m[i,j] =  -m_ij.size\n",
    "        else:\n",
    "            print('assertion handeled')\n",
    "            return\n",
    "            #break\n",
    "    return m\n",
    "\n",
    "def translate_clustering(clt, mapper):\n",
    "    return np.array([ mapper[i] for i in clt ])\n",
    "\n",
    "def accuracy(cm):\n",
    "    return np.trace(cm, dtype=float) / np.sum(cm)\n",
    "\n",
    "def rectify_label(labels, classes):\n",
    "    num_labels = len(np.unique(classes))\n",
    "    cm = confusion_matrix(classes, labels, labels=range(num_labels)) # gets the confusion matrix\n",
    "    cost_matrix = make_cost_matrix(labels, classes)\n",
    "    if cost_matrix is None:\n",
    "        return (None,None)\n",
    "    else:\n",
    "        m = Munkres()\n",
    "        indexes = m.compute(cost_matrix)\n",
    "        mapper = { old: new for (old, new) in indexes }\n",
    "        new_labels = translate_clustering(labels, mapper)\n",
    "        new_cm = confusion_matrix(classes, new_labels, labels=range(num_labels))\n",
    "        return new_labels,accuracy(new_cm)\n",
    "\n",
    "def arch():\n",
    "    encoding_dim = 390  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "    input_img = Input(shape=(400,))\n",
    "    encoded_layer_2 = Dense(397, activation='tanh')(input_img)\n",
    "    encoded_layer_3 = Dense(395, activation='tanh')(encoded_layer_2)\n",
    "    encoded_layer_4 = Dense(393, activation='tanh')(encoded_layer_3)\n",
    "    encoded = Dense(encoding_dim, activation='tanh')(encoded_layer_4)\n",
    "    decoded_layer_2 = Dense(393, activation='tanh')(encoded)\n",
    "    decoded_layer_3 = Dense(395, activation='tanh')(decoded_layer_2)\n",
    "    decoded_layer_4 = Dense(397, activation='tanh')(decoded_layer_3)\n",
    "    decoded = Dense(400, activation='tanh')(decoded_layer_4)\n",
    "    encoder=Model(input_img,encoded)\n",
    "    autoencoder=Model(input_img,decoded)\n",
    "    return encoder,encoding_dim,autoencoder\n",
    "\n",
    "\n",
    "\n",
    "def assign_func(z_test,z_ic):\n",
    "    dst = np.array(np.sum(((z_test-z_ic[0]) **2),axis=1))\n",
    "    for index in range(1, z_ic.shape[0]):\n",
    "        col = np.sum(((z_test- z_ic[index])**2), axis=1)\n",
    "        dst = np.vstack((dst, col))\n",
    "    dst = dst.T      \n",
    "    \n",
    "    mean_dst = np.mean(dst, axis=1)\n",
    "    q = np.maximum(0.0, np.tile(mean_dst, (dst.shape[1], 1)).T - dst)\n",
    "    #print(q.shape)\n",
    "    num_centers = q.shape[1]\n",
    "    weight = 1.0 / (q.sum(axis=0) + 1e-9)\n",
    "    weight *= num_centers / weight.sum()\n",
    "    q = (q ** 2.0) * weight\n",
    "    q = (q.T / (q.sum(axis=1) + B.epsilon())).T\n",
    "    return q\n",
    "\n",
    "def asl():\n",
    "    def myloss(y_true, y_pred):\n",
    "        l1norm= l1norm_func(y_pred,y_true)\n",
    "        l2norm= l2norm_func(y_pred,y_true)\n",
    "        orthonormal= orthonormality_func(y_pred)\n",
    "        structpreserve=structurePreserve_func(y_pred,alpha_trans1[g][:,:])\n",
    "        return orthonormal+l1norm+l2norm+structpreserve\n",
    "    return myloss\n",
    "\n",
    "def l1norm_func(z,nt):\n",
    "    q1=0.002*(tf.reduce_sum(tf.abs(tf.subtract(z,nt)),axis=1))\n",
    "    return q1\n",
    "\n",
    "def l2norm_func(z,nt):\n",
    "    q2=0.02*(tf.sqrt(tf.reduce_sum(tf.square(z-nt),axis=1)))\n",
    "    return q2\n",
    "\n",
    "def structurePreserve_func(z,ta):\n",
    "    tz=tf.transpose(z)\n",
    "    tz=tf.reshape(tz,(encoding_dim,batchSize))\n",
    "    taa=tf.transpose(ta)\n",
    "    taz=tf.matmul(tz,taa)\n",
    "    taz=tf.reshape(taz,(encoding_dim,batchSize))\n",
    "    q4=0.02*(tf.sqrt(tf.reduce_sum(tf.square(tz-taz))))\n",
    "    q4=tf.transpose(q4)\n",
    "    return q4\n",
    "\n",
    "\n",
    "def orthonormality_func(z):\n",
    "    z=[(z[i,:]/(tf.norm(z[i,:],2)))for i in range (batchSize)]\n",
    "    transz=tf.transpose(z)\n",
    "    q3=tf.tensordot(transz,z,axes=1)\n",
    "    I=tf.eye(encoding_dim)\n",
    "    q5=0.002*(tf.sqrt(tf.reduce_sum(tf.square(q3-I))))\n",
    "    return q5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eb79e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/itu-cvl/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "loading pre trained model\n",
      "0.9075 0.9466350858615871 0.9075 0.9261012598512598\n"
     ]
    }
   ],
   "source": [
    "\n",
    "encoder,encoding_dim,autoencoder=arch()\n",
    "print('loading pre trained model')\n",
    "encoder.load_weights('../../../checkpoints/chk_orl/sdsc_orl.ckpt')\n",
    "z_test=encoder.predict(x_train)\n",
    "ic= np.load('../../../checkpoints/chk_orl/sdsc_icorl.npy')\n",
    "assignment = assign_func(z_test, ic)\n",
    "predictedlabels = np.argmax(assignment, axis=1)\n",
    "rectified_label, acc=rectify_label(predictedlabels, y)\n",
    "nmi=sklearn.metrics.normalized_mutual_info_score(y, rectified_label)\n",
    "f1=sklearn.metrics.f1_score(y, rectified_label,average='micro')\n",
    "prec=sklearn.metrics.precision_score(y, rectified_label,average='weighted')\n",
    "print(acc,nmi,f1,prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d46e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
